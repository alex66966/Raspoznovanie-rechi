{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека, которая позволяет создавать модели нейронных сетей \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Позволяет создать массив фреймов аудиопотока \n",
    "import numpy as np\n",
    "import os\n",
    "# Связанные с numpy\n",
    "from IPython.display import Audio\n",
    "from IPython.core.display import HTML\n",
    "# Библиотека, которая позволяет рисовать спектрограмму частоты звука от времени\n",
    "# Работает с преобразованием Фурье \n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга wav-файлов \n",
    "import scipy.io.wavfile as wav\n",
    "# Мел частотные кепстральные коэффициенты (спектрограмма с мел-шкалой вместо оси у)\n",
    "# Строит характеристику частот от времени в сэмплах через STFT \n",
    "\n",
    "# LSTM - для вызова рекурсивной функции\n",
    "# Dense - для связи всех нейронов предыдущего слоя с текущим (выходным) слоем\n",
    "# Convolution - сверта слоев\n",
    "from keras.layers import LSTM, Dense, Convolution1D, Activation\n",
    "\n",
    "# Позволяет давать послойное описание модели \n",
    "from keras.models import Sequential\n",
    "# TimeDistributed - Один из способов работы с Dense \n",
    "# Bidirectional - получение информации не только от прошлого и самого себя, но от будущего  \n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "# Последовательность\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import fbank, mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Загрузим аудио и тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-20121125-pgp',\n",
       " '1981-20120705-haq',\n",
       " '1981-20120705-rjp',\n",
       " '1981-20120706-azq',\n",
       " '1981-20120706-hpa',\n",
       " '1981-20120706-kwo',\n",
       " '1981-20120706-rxa',\n",
       " '1981-20120706-rya',\n",
       " '1981-20120706-vmc',\n",
       " '1981-20120706-zfp']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('Voxforge')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\IQ-6\\\\Documents\\\\распознование речи'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = { 'а': 1,\n",
    "               'б': 2,\n",
    "               'в': 3,\n",
    "               'г': 4,\n",
    "               'д': 5,\n",
    "               'е': 6,\n",
    "               'ё': 7,\n",
    "               'ж': 8,\n",
    "               'з': 9,\n",
    "               'и': 10,\n",
    "               'й': 11,\n",
    "               'к': 12,\n",
    "               'л': 13,\n",
    "               'м': 14,\n",
    "               'н': 15,\n",
    "               'о': 16,\n",
    "               'п': 17,\n",
    "               'р': 18,\n",
    "               'с': 19,\n",
    "               'т': 20,\n",
    "               'у': 21,\n",
    "               'ф': 22,\n",
    "               'х': 23,\n",
    "               'ц': 24,\n",
    "               'ч': 25,\n",
    "               'ш': 26,\n",
    "               'щ': 27,\n",
    "               'ъ': 28,\n",
    "               'ы': 29,\n",
    "               'ь': 30,\n",
    "               'э': 31,\n",
    "               'ю': 32,\n",
    "               'я': 33\n",
    "             }\n",
    "# Преобразование в словарь \n",
    "inv_mapping = dict(zip(vocabulary.values(), vocabulary.keys()))\n",
    "inv_mapping[34]='<пробел>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru_0022.wav Voxforge//1-20121125-pgp//txt//ru_0022.txt\n",
      "ru_0024.wav Voxforge//1-20121125-pgp//txt//ru_0024.txt\n",
      "ru_0025.wav Voxforge//1-20121125-pgp//txt//ru_0025.txt\n",
      "ru_0027.wav Voxforge//1-20121125-pgp//txt//ru_0027.txt\n",
      "ru_0030.wav Voxforge//1-20121125-pgp//txt//ru_0030.txt\n",
      "ru_0031.wav Voxforge//1-20121125-pgp//txt//ru_0031.txt\n",
      "ru_0032.wav Voxforge//1-20121125-pgp//txt//ru_0032.txt\n",
      "ru_0033.wav Voxforge//1-20121125-pgp//txt//ru_0033.txt\n",
      "ru_0034.wav Voxforge//1-20121125-pgp//txt//ru_0034.txt\n",
      "ru_0035.wav Voxforge//1-20121125-pgp//txt//ru_0035.txt\n",
      "ru_0076.wav Voxforge//1981-20120705-haq//txt//ru_0076.txt\n",
      "ru_0077.wav Voxforge//1981-20120705-haq//txt//ru_0077.txt\n",
      "ru_0078.wav Voxforge//1981-20120705-haq//txt//ru_0078.txt\n",
      "ru_0079.wav Voxforge//1981-20120705-haq//txt//ru_0079.txt\n",
      "ru_0080.wav Voxforge//1981-20120705-haq//txt//ru_0080.txt\n",
      "ru_0081.wav Voxforge//1981-20120705-haq//txt//ru_0081.txt\n",
      "ru_0082.wav Voxforge//1981-20120705-haq//txt//ru_0082.txt\n",
      "ru_0084.wav Voxforge//1981-20120705-haq//txt//ru_0084.txt\n",
      "ru_0085.wav Voxforge//1981-20120705-haq//txt//ru_0085.txt\n",
      "ru_0086.wav Voxforge//1981-20120705-haq//txt//ru_0086.txt\n",
      "ru_0040.wav Voxforge//1981-20120705-rjp//txt//ru_0040.txt\n",
      "ru_0041.wav Voxforge//1981-20120705-rjp//txt//ru_0041.txt\n",
      "ru_0042.wav Voxforge//1981-20120705-rjp//txt//ru_0042.txt\n",
      "ru_0043.wav Voxforge//1981-20120705-rjp//txt//ru_0043.txt\n",
      "ru_0044.wav Voxforge//1981-20120705-rjp//txt//ru_0044.txt\n",
      "ru_0045.wav Voxforge//1981-20120705-rjp//txt//ru_0045.txt\n",
      "ru_0046.wav Voxforge//1981-20120705-rjp//txt//ru_0046.txt\n",
      "ru_0049.wav Voxforge//1981-20120705-rjp//txt//ru_0049.txt\n",
      "ru_0050.wav Voxforge//1981-20120705-rjp//txt//ru_0050.txt\n",
      "ru_0051.wav Voxforge//1981-20120705-rjp//txt//ru_0051.txt\n",
      "ru_0030.wav Voxforge//1981-20120706-azq//txt//ru_0030.txt\n",
      "ru_0031.wav Voxforge//1981-20120706-azq//txt//ru_0031.txt\n",
      "ru_0032.wav Voxforge//1981-20120706-azq//txt//ru_0032.txt\n",
      "ru_0033.wav Voxforge//1981-20120706-azq//txt//ru_0033.txt\n",
      "ru_0034.wav Voxforge//1981-20120706-azq//txt//ru_0034.txt\n",
      "ru_0035.wav Voxforge//1981-20120706-azq//txt//ru_0035.txt\n",
      "ru_0036.wav Voxforge//1981-20120706-azq//txt//ru_0036.txt\n",
      "ru_0037.wav Voxforge//1981-20120706-azq//txt//ru_0037.txt\n",
      "ru_0038.wav Voxforge//1981-20120706-azq//txt//ru_0038.txt\n",
      "ru_0039.wav Voxforge//1981-20120706-azq//txt//ru_0039.txt\n",
      "ru_0012.wav Voxforge//1981-20120706-hpa//txt//ru_0012.txt\n",
      "ru_0013.wav Voxforge//1981-20120706-hpa//txt//ru_0013.txt\n",
      "ru_0014.wav Voxforge//1981-20120706-hpa//txt//ru_0014.txt\n",
      "ru_0015.wav Voxforge//1981-20120706-hpa//txt//ru_0015.txt\n",
      "ru_0016.wav Voxforge//1981-20120706-hpa//txt//ru_0016.txt\n",
      "ru_0017.wav Voxforge//1981-20120706-hpa//txt//ru_0017.txt\n",
      "ru_0018.wav Voxforge//1981-20120706-hpa//txt//ru_0018.txt\n",
      "ru_0022.wav Voxforge//1981-20120706-hpa//txt//ru_0022.txt\n",
      "ru_0024.wav Voxforge//1981-20120706-hpa//txt//ru_0024.txt\n",
      "ru_0025.wav Voxforge//1981-20120706-hpa//txt//ru_0025.txt\n",
      "ru_0068.wav Voxforge//1981-20120706-kwo//txt//ru_0068.txt\n",
      "ru_0069.wav Voxforge//1981-20120706-kwo//txt//ru_0069.txt\n",
      "ru_0070.wav Voxforge//1981-20120706-kwo//txt//ru_0070.txt\n",
      "ru_0071.wav Voxforge//1981-20120706-kwo//txt//ru_0071.txt\n",
      "ru_0073.wav Voxforge//1981-20120706-kwo//txt//ru_0073.txt\n",
      "ru_0074.wav Voxforge//1981-20120706-kwo//txt//ru_0074.txt\n",
      "ru_0075.wav Voxforge//1981-20120706-kwo//txt//ru_0075.txt\n",
      "ru_0076.wav Voxforge//1981-20120706-kwo//txt//ru_0076.txt\n",
      "ru_0077.wav Voxforge//1981-20120706-kwo//txt//ru_0077.txt\n",
      "ru_0078.wav Voxforge//1981-20120706-kwo//txt//ru_0078.txt\n",
      "ru_0003.wav Voxforge//1981-20120706-rxa//txt//ru_0003.txt\n",
      "ru_0004.wav Voxforge//1981-20120706-rxa//txt//ru_0004.txt\n",
      "ru_0005.wav Voxforge//1981-20120706-rxa//txt//ru_0005.txt\n",
      "ru_0006.wav Voxforge//1981-20120706-rxa//txt//ru_0006.txt\n",
      "ru_0008.wav Voxforge//1981-20120706-rxa//txt//ru_0008.txt\n",
      "ru_0009.wav Voxforge//1981-20120706-rxa//txt//ru_0009.txt\n",
      "ru_0010.wav Voxforge//1981-20120706-rxa//txt//ru_0010.txt\n",
      "ru_0011.wav Voxforge//1981-20120706-rxa//txt//ru_0011.txt\n",
      "ru_0012.wav Voxforge//1981-20120706-rxa//txt//ru_0012.txt\n",
      "ru_0013.wav Voxforge//1981-20120706-rxa//txt//ru_0013.txt\n",
      "ru_0003.wav Voxforge//1981-20120706-rya//txt//ru_0003.txt\n",
      "ru_0004.wav Voxforge//1981-20120706-rya//txt//ru_0004.txt\n",
      "ru_0005.wav Voxforge//1981-20120706-rya//txt//ru_0005.txt\n",
      "ru_0006.wav Voxforge//1981-20120706-rya//txt//ru_0006.txt\n",
      "ru_0008.wav Voxforge//1981-20120706-rya//txt//ru_0008.txt\n",
      "ru_0009.wav Voxforge//1981-20120706-rya//txt//ru_0009.txt\n",
      "ru_0010.wav Voxforge//1981-20120706-rya//txt//ru_0010.txt\n",
      "ru_0011.wav Voxforge//1981-20120706-rya//txt//ru_0011.txt\n",
      "ru_0012.wav Voxforge//1981-20120706-rya//txt//ru_0012.txt\n",
      "ru_0013.wav Voxforge//1981-20120706-rya//txt//ru_0013.txt\n",
      "ru_0073.wav Voxforge//1981-20120706-vmc//txt//ru_0073.txt\n",
      "ru_0074.wav Voxforge//1981-20120706-vmc//txt//ru_0074.txt\n",
      "ru_0075.wav Voxforge//1981-20120706-vmc//txt//ru_0075.txt\n",
      "ru_0076.wav Voxforge//1981-20120706-vmc//txt//ru_0076.txt\n",
      "ru_0077.wav Voxforge//1981-20120706-vmc//txt//ru_0077.txt\n",
      "ru_0078.wav Voxforge//1981-20120706-vmc//txt//ru_0078.txt\n",
      "ru_0079.wav Voxforge//1981-20120706-vmc//txt//ru_0079.txt\n",
      "ru_0080.wav Voxforge//1981-20120706-vmc//txt//ru_0080.txt\n",
      "ru_0081.wav Voxforge//1981-20120706-vmc//txt//ru_0081.txt\n",
      "ru_0082.wav Voxforge//1981-20120706-vmc//txt//ru_0082.txt\n",
      "ru_0084.wav Voxforge//1981-20120706-zfp//txt//ru_0084.txt\n",
      "ru_0085.wav Voxforge//1981-20120706-zfp//txt//ru_0085.txt\n",
      "ru_0086.wav Voxforge//1981-20120706-zfp//txt//ru_0086.txt\n",
      "ru_0087.wav Voxforge//1981-20120706-zfp//txt//ru_0087.txt\n",
      "ru_0088.wav Voxforge//1981-20120706-zfp//txt//ru_0088.txt\n",
      "ru_0089.wav Voxforge//1981-20120706-zfp//txt//ru_0089.txt\n",
      "ru_0093.wav Voxforge//1981-20120706-zfp//txt//ru_0093.txt\n",
      "ru_0094.wav Voxforge//1981-20120706-zfp//txt//ru_0094.txt\n",
      "ru_0095.wav Voxforge//1981-20120706-zfp//txt//ru_0095.txt\n",
      "ru_0099.wav Voxforge//1981-20120706-zfp//txt//ru_0099.txt\n",
      "ru_0084.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0084.txt\n",
      "ru_0085.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0085.txt\n",
      "ru_0086.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0086.txt\n",
      "ru_0087.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0087.txt\n",
      "ru_0088.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0088.txt\n",
      "ru_0089.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0089.txt\n",
      "ru_0093.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0093.txt\n",
      "ru_0094.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0094.txt\n",
      "ru_0095.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0095.txt\n",
      "ru_0099.wav Voxforge//4ertus2-20101217-zoo//txt//ru_0099.txt\n",
      "ru_0001.wav Voxforge//AAS-20101109-lyn//txt//ru_0001.txt\n",
      "ru_0002.wav Voxforge//AAS-20101109-lyn//txt//ru_0002.txt\n",
      "ru_0003.wav Voxforge//AAS-20101109-lyn//txt//ru_0003.txt\n",
      "ru_0004.wav Voxforge//AAS-20101109-lyn//txt//ru_0004.txt\n",
      "ru_0005.wav Voxforge//AAS-20101109-lyn//txt//ru_0005.txt\n",
      "ru_0006.wav Voxforge//AAS-20101109-lyn//txt//ru_0006.txt\n",
      "ru_0094.wav Voxforge//AAS-20101109-lyn//txt//ru_0094.txt\n",
      "ru_0095.wav Voxforge//AAS-20101109-lyn//txt//ru_0095.txt\n",
      "ru_0099.wav Voxforge//AAS-20101109-lyn//txt//ru_0099.txt\n",
      "ru_0100.wav Voxforge//AAS-20101109-lyn//txt//ru_0100.txt\n",
      "ru_0051.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0051.txt\n",
      "ru_0052.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0052.txt\n",
      "ru_0053.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0053.txt\n",
      "ru_0054.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0054.txt\n",
      "ru_0055.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0055.txt\n",
      "ru_0056.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0056.txt\n",
      "ru_0058.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0058.txt\n",
      "ru_0059.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0059.txt\n",
      "ru_0060.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0060.txt\n",
      "ru_0061.wav Voxforge//akaalxcoaakaInterocitor-20100322-dqk//txt//ru_0061.txt\n",
      "ru_0022.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0022.txt\n",
      "ru_0024.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0024.txt\n",
      "ru_0025.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0025.txt\n",
      "ru_0027.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0027.txt\n",
      "ru_0030.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0030.txt\n",
      "ru_0031.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0031.txt\n",
      "ru_0032.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0032.txt\n",
      "ru_0033.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0033.txt\n",
      "ru_0034.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0034.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru_0035.wav Voxforge//akaalxcoaakaInterocitor-20100322-naz//txt//ru_0035.txt\n",
      "ru_0067.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0067.txt\n",
      "ru_0068.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0068.txt\n",
      "ru_0069.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0069.txt\n",
      "ru_0070.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0070.txt\n",
      "ru_0071.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0071.txt\n",
      "ru_0073.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0073.txt\n",
      "ru_0074.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0074.txt\n",
      "ru_0075.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0075.txt\n",
      "ru_0076.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0076.txt\n",
      "ru_0077.wav Voxforge//akaalxcoaakaInterocitor-20100324-hyp//txt//ru_0077.txt\n"
     ]
    }
   ],
   "source": [
    "#path1 = os.getcwd()    \n",
    "y = []\n",
    "x = []\n",
    "os.chdir(path1) #меняем директорию\n",
    "\n",
    "for speaker_folder in os.listdir('Voxforge')[0:15]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    speaker_folder_wav = 'Voxforge//'+speaker_folder+'//wav//'\n",
    "    speaker_folder_txt = 'Voxforge//'+speaker_folder+'//txt//'\n",
    "    \n",
    "    for wav_file in os.listdir(speaker_folder_wav): \n",
    "        \n",
    "        try:\n",
    "            text_file = speaker_folder_txt + wav_file.split('.')[0] + '.txt'\n",
    "       \n",
    "            with open(text_file, 'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    if line[0] == ';':\n",
    "                        continue\n",
    "                \n",
    "\n",
    "\n",
    "                original = ' '.join(str(line, 'utf-8').strip().lower().split(' ')).replace('.', '').replace(\"'\", '').replace('-', '').replace(',','')\n",
    "    # Меняем пробелы на более длинные \n",
    "                targets = original.replace(' ', '  ')\n",
    "    # Разделяем слова через пробелы \n",
    "                targets = targets.split(' ')\n",
    "    # Объявляем строку и начинаем ее с пробела\n",
    "                stroka=[34]\n",
    "                for i in targets:\n",
    "                    i1=i.encode(\"UTF-8\")\n",
    "                    for j in range(0,len(i1),2):\n",
    "    # Через вызов decode() получаем буквы и добавляем их в строку \n",
    "                        stroka.append(vocabulary.get(i1[j:j+2].decode(\"utf-8\"),34))\n",
    "                    if stroka[-1] != 34:\n",
    "    # Закончили с буквами\n",
    "    # Добавляем в конец строки пробел\n",
    "                        stroka.append(34)\n",
    "    # Обработка звука\n",
    "                fs, audio = wav.read(speaker_folder_wav + wav_file)\n",
    "    # Ищем отличительные черты через мел-кепстральные коэффициенты и преобразование Фурье            \n",
    "    # Мел-шкала отражает главным образом высоту звука, от которой, в свою очередь, его частота. \n",
    "    # Эта зависимость нелинейна, особенно при низких частотах.\n",
    "    # Различные звуки имеют различные частоты и, соответственно, по-разному отображаются\n",
    "    # на мел-шкале.\n",
    "\n",
    "# выделяет ту часть которая важна человеку \n",
    "                features = mfcc(audio, \n",
    "                                samplerate=fs,\n",
    "                                winlen=0.2,   #размер окна 0,2 сек\n",
    "                                winstep=0.1, # шаг 0,1 сек\n",
    "                                numcep=16, # число мелов 16\n",
    "                                lowfreq=50, #самая низкая чистота hg\n",
    "                                nfft=4096 # число синусоид\n",
    "                               )\n",
    "                mean_scale = np.mean(features, axis=0) #нормировка\n",
    "                std_scale = np.std(features, axis=0)\n",
    "\n",
    "                features = (features - mean_scale[np.newaxis, :]) / std_scale[np.newaxis, :]\n",
    "                seq_len = features.shape[0]\n",
    "            \n",
    "\n",
    "## возьмем только похожие по размеру, около 100 букв\n",
    "#                 if seq_len > 950 and seq_len < 1050 and len (stroka) > 90 and len (stroka) < 110:\n",
    "                \n",
    "                x.append(features) #в x(массив) добавляем аудиозапись \n",
    "                y.append(stroka)  # текст в цифровом формате \n",
    "                print(wav_file,text_file ) # скачивание \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "      #      \n",
    "            print('Error ', speaker_folder, wav_file, text_file)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\IQ-6\\\\Documents\\\\распознование речи'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 63\n"
     ]
    }
   ],
   "source": [
    "# приведем к одной длине аудио записи, заполнив нулями?\n",
    "\n",
    "lens_mfcc = []\n",
    "for i in range(len(x)):\n",
    "    lens_mfcc.append(x[i].shape[0])\n",
    "    \n",
    "print(max(lens_mfcc), min(lens_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "for i in range(len(x)):\n",
    "    x1.append(np.zeros((max(lens_mfcc), 16)  ))\n",
    "    x1[i][0:x[i].shape[0], 0:x[i].shape[1]]  =   x[i][0:x[i].shape[0], 0:x[i].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1[0:(x[i].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 209, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C x покончено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 43\n"
     ]
    }
   ],
   "source": [
    "lens_texts = []\n",
    "for i in range(len(y)):\n",
    "    lens_texts.append(len(y[i]))\n",
    "    \n",
    "print(max(lens_texts), min(lens_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = []\n",
    "for i in range(len(y)):\n",
    "  #  print(x[i].shape)\n",
    "    #try:\n",
    "        y1.append(np.zeros(max(lens_texts)  ))\n",
    "        y1[i][0:len(y[i])]  =   y[i][0:len(y[i])]\n",
    "   # except:\n",
    "    #    print(len(y[i]), len(y1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 180)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array(y1) \n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 209, 16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 180, 35)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary = to_categorical(y1)\n",
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 209, 16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 180, 35)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_new=[]\n",
    "# for j in range(x1.shape[0]):\n",
    "#     k1=x1.shape[1]//y_binary.shape[1]\n",
    "#     for i in range(y_binary.shape[1]-1):\n",
    "#         for k in range(x1.shape[2]):\n",
    "#             zxc=np.mean(x1 [j , i*k1:(i+1)*k1 ,k])\n",
    "#             x_new.append(zxc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_new1=np.array(x_new)\n",
    "# x_new2=x_new1.reshape(2,-1,16)\n",
    "# x_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 180, 35)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 209, 16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x1, y_binary, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(128, return_sequences=True))  \n",
    "model.add(LSTM(300, return_sequences=True))  \n",
    "model.add(TimeDistributed(Dense(34 + 1)))\n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_1 to have shape (209, 35) but got array with shape (180, 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9cfce525ef4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Rech\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Rech\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Rech\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_1 to have shape (209, 35) but got array with shape (180, 35)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 102, 35)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_new2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "34\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "6\n",
      "6\n",
      "6\n",
      "14\n",
      "14\n",
      "14\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "34\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "10\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "34\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range(102):\n",
    "    print(np.argmax(model.predict(x_new2)[0,i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2775\n"
     ]
    }
   ],
   "source": [
    "        pred1 = model.predict(x_new2)\n",
    "        #pred_class = (np.where(pred1 == np.amax(pred1))[1])\n",
    "        pred_class = np.argmax(pred1)\n",
    "        print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2 = Sequential()\n",
    "#     LSTM(units, activation = 'tanh', recurrent_activation= 'sigmoid', use_bias = true,\n",
    "#          kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', \n",
    "#          bias_initializer = 'zeros', ... )\n",
    "# Слои двунаправленных нейронов \n",
    "    model2.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2), input_shape=(None, 16)))\n",
    "    model2.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2)))\n",
    "# Выходной слой \n",
    "    model2.add(TimeDistributed(Dense(len(inv_mapping) + 1, activation = 'relu') ))\n",
    "    #model.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_5 (Bidirection (None, None, 256)         148480    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, None, 256)         394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 35)          8995      \n",
      "=================================================================\n",
      "Total params: 551,715\n",
      "Trainable params: 551,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 7.8301 - accuracy: 0.2526\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 4.9856 - accuracy: 0.5149\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 4.6153 - accuracy: 0.5305\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 4.4173 - accuracy: 0.5360\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 4.2684 - accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(x_train, y_train[:,:172,:], epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "10\n",
      "10\n",
      "10\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-cd0fd73cc906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m102\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/keras_tf/kerastf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/keras_tf/kerastf/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras_tf/kerastf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/keras_tf/kerastf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(102):\n",
    "    print(\n",
    "        np.argmax(model2.predict(x1)[0,i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-8e0747ba5e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '4'"
     ]
    }
   ],
   "source": [
    "vocabulary['4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( LSTM( 128, input_shape=(180, 13), return_sequences=True))\n",
    "# (bs, 45, 512)\n",
    "model.add( LSTM( 128, return_sequences=True)) # SET HERE\n",
    "# (bs, 512)\n",
    "model.add( (Dense(35)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[:,0:180,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.predict(x_train[0:1,0:180,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1 = audio.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(audio1 , sr=fs, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(log_S, sr=fs, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel power spectrogram ')\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1 = librosa.feature.mfcc(S=log_S, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta2_mfcc = librosa.feature.delta(mfcc1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(delta2_mfcc).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = mfcc(audio, samplerate=fs, lowfreq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведение вычислительных процессов для частей графа \n",
    "# Бесконенчый цикл, пока выполняется условие\n",
    "# Сессия позволяет хранить значения графа и производить с ними вычисления \n",
    "with tf.Session(graph = graph) as session:\n",
    "\n",
    "# Если нет чекпоинтов (chekpoint = None) \n",
    "# Инициализирум веса и биасы\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "\n",
    "        for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_train1, y_train1, 100):\n",
    "            feed_dict = {\n",
    "                input_X: X_batch,\n",
    "                labels: y_batch,\n",
    "\n",
    "                seq_lens: seq_lens_batch\n",
    "            }\n",
    "            \n",
    "            \n",
    "# train_loss = session.run([ctc_loss])\n",
    "# \n",
    "            train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "        print(\"train_decoded\", train_loss)\n",
    "        if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "                print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "#                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "                saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "#         print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "        ret = decode(train_decoded, inv_mapping)[:10]\n",
    "        for i in range(len(ret)):\n",
    "            print(str(ret[i])),\n",
    "        print(time.ctime())\n",
    "        decode1(y_batch_orig[0],inv_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
