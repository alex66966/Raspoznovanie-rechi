{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека, которая позволяет создавать модели нейронных сетей \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Позволяет создать массив фреймов аудиопотока \n",
    "import numpy as np\n",
    "import os\n",
    "# Связанные с numpy\n",
    "from IPython.display import Audio\n",
    "from IPython.core.display import HTML\n",
    "# Библиотека, которая позволяет рисовать спектрограмму частоты звука от времени\n",
    "# Работает с преобразованием Фурье \n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Для парсинга wav-файлов \n",
    "import scipy.io.wavfile as wav\n",
    "# Мел частотные кепстральные коэффициенты (спектрограмма с мел-шкалой вместо оси у)\n",
    "# Строит характеристику частот от времени в сэмплах через STFT \n",
    "\n",
    "# LSTM - для вызова рекурсивной функции\n",
    "# Dense - для связи всех нейронов предыдущего слоя с текущим (выходным) слоем\n",
    "# Convolution - сверта слоев\n",
    "from keras.layers import LSTM, Dense, Convolution1D, Activation\n",
    "\n",
    "# Позволяет давать послойное описание модели \n",
    "from keras.models import Sequential\n",
    "# TimeDistributed - Один из способов работы с Dense \n",
    "# Bidirectional - получение информации не только от прошлого и самого себя, но от будущего  \n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "# Последовательность\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'python_speech_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-84a26f7e8d15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpython_speech_features\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfbank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'python_speech_features'"
     ]
    }
   ],
   "source": [
    "from python_speech_features import fbank, mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Загрузим аудио и тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-20121125-pgp',\n",
       " '1981-20120705-haq',\n",
       " '1981-20120705-rjp',\n",
       " '1981-20120706-azq',\n",
       " '1981-20120706-hpa',\n",
       " '1981-20120706-kwo',\n",
       " '1981-20120706-rxa',\n",
       " '1981-20120706-rya',\n",
       " '1981-20120706-vmc',\n",
       " '1981-20120706-zfp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('Voxforge')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'C:\\\\Users\\\\Nicolas\\\\Downloads\\\\rus_speach_recognition-master\\\\Rus-LSTM-CTC-VoxForge\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = { 'а': 1,\n",
    "               'б': 2,\n",
    "               'в': 3,\n",
    "               'г': 4,\n",
    "               'д': 5,\n",
    "               'е': 6,\n",
    "               'ё': 7,\n",
    "               'ж': 8,\n",
    "               'з': 9,\n",
    "               'и': 10,\n",
    "               'й': 11,\n",
    "               'к': 12,\n",
    "               'л': 13,\n",
    "               'м': 14,\n",
    "               'н': 15,\n",
    "               'о': 16,\n",
    "               'п': 17,\n",
    "               'р': 18,\n",
    "               'с': 19,\n",
    "               'т': 20,\n",
    "               'у': 21,\n",
    "               'ф': 22,\n",
    "               'х': 23,\n",
    "               'ц': 24,\n",
    "               'ч': 25,\n",
    "               'ш': 26,\n",
    "               'щ': 27,\n",
    "               'ъ': 28,\n",
    "               'ы': 29,\n",
    "               'ь': 30,\n",
    "               'э': 31,\n",
    "               'ю': 32,\n",
    "               'я': 33\n",
    "             }\n",
    "# Преобразование в словарь \n",
    "inv_mapping = dict(zip(vocabulary.values(), vocabulary.keys()))\n",
    "inv_mapping[34]='<пробел>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'C:\\\\Users\\\\Nicolas\\\\Downloads\\\\rus_speach_recognition-master\\\\Rus-LSTM-CTC-VoxForge\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-214e51e5bea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspeaker_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Voxforge'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'C:\\\\Users\\\\Nicolas\\\\Downloads\\\\rus_speach_recognition-master\\\\Rus-LSTM-CTC-VoxForge\\\\'"
     ]
    }
   ],
   "source": [
    "#path1 = os.getcwd()    \n",
    "y = []\n",
    "x = []\n",
    "os.chdir(path1)\n",
    "\n",
    "for speaker_folder in os.listdir('Voxforge')[0:15]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    speaker_folder_wav = 'Voxforge//'+speaker_folder+'//wav//'\n",
    "    speaker_folder_txt = 'Voxforge//'+speaker_folder+'//txt//'\n",
    "    \n",
    "    for wav_file in os.listdir(speaker_folder_wav): \n",
    "        try:\n",
    "            text_file = speaker_folder_txt + wav_file.split('.')[0] + '.txt'\n",
    "       \n",
    "            with open(text_file, 'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    if line[0] == ';':\n",
    "                        continue\n",
    "                \n",
    "\n",
    "\n",
    "                original = ' '.join(str(line, 'utf-8').strip().lower().split(' ')).replace('.', '').replace(\"'\", '').replace('-', '').replace(',','')\n",
    "    # Меняем пробелы на более длинные \n",
    "                targets = original.replace(' ', '  ')\n",
    "    # Разделяем слова через пробелы \n",
    "                targets = targets.split(' ')\n",
    "    # Объявляем строку и начинаем ее с пробела\n",
    "                stroka=[34]\n",
    "                for i in targets:\n",
    "                    i1=i.encode(\"UTF-8\")\n",
    "                    for j in range(0,len(i1),2):\n",
    "    # Через вызов decode() получаем буквы и добавляем их в строку \n",
    "                        stroka.append(vocabulary.get(i1[j:j+2].decode(\"utf-8\"),34))\n",
    "                    if stroka[-1] != 34:\n",
    "    # Закончили с буквами\n",
    "    # Добавляем в конец строки пробел\n",
    "                        stroka.append(34)\n",
    "    # Обработка звука\n",
    "                fs, audio = wav.read(speaker_folder_wav + wav_file)\n",
    "    # Ищем отличительные черты через мел-кепстральные коэффициенты и преобразование Фурье            \n",
    "    # Мел-шкала отражает главным образом высоту звука, от которой, в свою очередь, его частота. \n",
    "    # Эта зависимость нелинейна, особенно при низких частотах.\n",
    "    # Различные звуки имеют различные частоты и, соответственно, по-разному отображаются\n",
    "    # на мел-шкале.\n",
    "\n",
    "\n",
    "                features = mfcc(audio, samplerate=fs, lowfreq=50)\n",
    "                mean_scale = np.mean(features, axis=0)\n",
    "                std_scale = np.std(features, axis=0)\n",
    "\n",
    "                features = (features - mean_scale[np.newaxis, :]) / std_scale[np.newaxis, :]\n",
    "                seq_len = features.shape[0]\n",
    "            \n",
    "\n",
    "## возьмем только похожие по размеру, около 100 букв\n",
    "                if seq_len > 950 and seq_len < 1050 and len (stroka) > 90 and len (stroka) < 110:\n",
    "                    x.append(features)\n",
    "                    y.append(stroka)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "      #      \n",
    "            print('Error ', speaker_folder, wav_file, text_file)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем к одной длине, заполнив нулями?\n",
    "\n",
    "lens_mfcc = []\n",
    "for i in range(len(x)):\n",
    "    lens_mfcc.append(x[i].shape[0])\n",
    "    \n",
    "print(max(lens_mfcc), min(lens_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "for i in range(len(x)):\n",
    "    x1.append(np.zeros((max(lens_mfcc), 13)  ))\n",
    "    x1[i][0:x[i].shape[0], 0:x[i].shape[1]]  =   x[i][0:x[i].shape[0], 0:x[i].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1[0:(x[i].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C x покончено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_texts = []\n",
    "for i in range(len(y)):\n",
    "    lens_texts.append(len(y[i]))\n",
    "    \n",
    "print(max(lens_texts), min(lens_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(max(lens_texts)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = []\n",
    "for i in range(len(y)):\n",
    "  #  print(x[i].shape)\n",
    "    #try:\n",
    "        y1.append(np.zeros(max(lens_texts)  ))\n",
    "        y1[i][0:len(y[i])]  =   y[i][0:len(y[i])]\n",
    "   # except:\n",
    "    #    print(len(y[i]), len(y1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(y1) \n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = to_categorical(y1)\n",
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[:,0:108,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x1[:,0:108,:], y_binary, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(128, return_sequences=True))  \n",
    "model.add(LSTM(300, return_sequences=True))  \n",
    "model.add(TimeDistributed(Dense(34 + 1)))\n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2 = Sequential()\n",
    "#     LSTM(units, activation = 'tanh', recurrent_activation= 'sigmoid', use_bias = true,\n",
    "#          kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', \n",
    "#          bias_initializer = 'zeros', ... )\n",
    "# Слои двунаправленных нейронов \n",
    "    model2.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2), input_shape=(None, 13)))\n",
    "    model2.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2)))\n",
    "# Выходной слой \n",
    "    model2.add(TimeDistributed(Dense(len(inv_mapping) + 1, activation = 'relu') ))\n",
    "    #model.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(x_train, y_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( LSTM( 128, input_shape=(180, 13), return_sequences=True))\n",
    "# (bs, 45, 512)\n",
    "model.add( LSTM( 128, return_sequences=True)) # SET HERE\n",
    "# (bs, 512)\n",
    "model.add( (Dense(35)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[:,0:180,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.predict(x_train[0:1,0:180,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1 = audio.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(audio1 , sr=fs, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(log_S, sr=fs, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel power spectrogram ')\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1 = librosa.feature.mfcc(S=log_S, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta2_mfcc = librosa.feature.delta(mfcc1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(delta2_mfcc).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = mfcc(audio, samplerate=fs, lowfreq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведение вычислительных процессов для частей графа \n",
    "# Бесконенчый цикл, пока выполняется условие\n",
    "# Сессия позволяет хранить значения графа и производить с ними вычисления \n",
    "with tf.Session(graph = graph) as session:\n",
    "\n",
    "# Если нет чекпоинтов (chekpoint = None) \n",
    "# Инициализирум веса и биасы\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "\n",
    "        for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_train1, y_train1, 100):\n",
    "            feed_dict = {\n",
    "                input_X: X_batch,\n",
    "                labels: y_batch,\n",
    "\n",
    "                seq_lens: seq_lens_batch\n",
    "            }\n",
    "            \n",
    "            \n",
    "# train_loss = session.run([ctc_loss])\n",
    "# \n",
    "            train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "        print(\"train_decoded\", train_loss)\n",
    "        if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "                print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "#                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "                saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "#         print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "        ret = decode(train_decoded, inv_mapping)[:10]\n",
    "        for i in range(len(ret)):\n",
    "            print(str(ret[i])),\n",
    "        print(time.ctime())\n",
    "        decode1(y_batch_orig[0],inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
